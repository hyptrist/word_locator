{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sns\n",
    "%matplotlib inline\n",
    "import re\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have heard 200 times about the witch and tales of witchcraft @shruti. Oh My Goodness!!!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str='I have heard 200 times about the witch and tales of witchcraft @shruti. Oh My Goodness!!!'\n",
    "str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(str1):\n",
    "    #word=re.sub(r'^RT[\\s]+','',str1)\n",
    "    #word=re.sub(r'\\$\\w*','',word)\n",
    "    #word=re.sub(r'https?:\\/\\/.*[\\r\\n]*','',str1)\n",
    "    #word=re.sub(r'#','',str1)\n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens=tokenizer.tokenize(str1)\n",
    "    word_clean=[]\n",
    "    for words in tweet_tokens:\n",
    "        if words not in string.punctuation:\n",
    "            word_clean.append(words)\n",
    "    return word_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'heard',\n",
       " '200',\n",
       " 'times',\n",
       " 'about',\n",
       " 'the',\n",
       " 'witch',\n",
       " 'and',\n",
       " 'tales',\n",
       " 'of',\n",
       " 'witchcraft',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'goodness']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweet(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language',\n",
       " 'is',\n",
       " 'less',\n",
       " 'about',\n",
       " 'words',\n",
       " 'and',\n",
       " 'more',\n",
       " 'about',\n",
       " 'the',\n",
       " 'meaning',\n",
       " 'behind',\n",
       " 'them',\n",
       " 'if',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'your',\n",
       " 'time',\n",
       " 'learning',\n",
       " 'vocabulary',\n",
       " 'and',\n",
       " 'grammar',\n",
       " 'you',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'fluently',\n",
       " 'speak',\n",
       " 'a',\n",
       " 'language',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'little',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'these',\n",
       " 'short',\n",
       " 'stories',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'big',\n",
       " 'ideas',\n",
       " 'in',\n",
       " 'context']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence='@apoorva Language is less about words and more about the meaning behind them. If you spend all your time learning vocabulary and grammar, you will never be able to fluently speak a language because you will have little to talk about. These short stories give you the opportunity to understand big ideas in context.'\n",
    "tok=clean_tweet(sentence)\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fndwrd=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tok:\n",
    "    if (wn.synsets(i)):\n",
    "        fndwrd.append(i)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('be.v.01'), Synset('be.v.02'), Synset('be.v.03'), Synset('exist.v.01'), Synset('be.v.05'), Synset('equal.v.01'), Synset('constitute.v.01'), Synset('be.v.08'), Synset('embody.v.02'), Synset('be.v.10'), Synset('be.v.11'), Synset('be.v.12'), Synset('cost.v.01')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(wn.synsets('is'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fndwrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Shreya\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words as nltk_words\n",
    "def is_english_word(word):\n",
    "    # creation of this dictionary would be done outside of \n",
    "    #     the function because you only need to do it once.\n",
    "    dictionary = dict.fromkeys(nltk_words.words(), None)\n",
    "    try:\n",
    "        x = dictionary[word]\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom nltk.corpus import wordnet as wn\\ndef gis_english_word(word):\\n    dictionary = dict.fromkeys(wn.words(), None)\\n    try:\\n        x = dictionary[word]\\n        return True\\n    except KeyError:\\n        return False\\n'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from nltk.corpus import wordnet as wn\n",
    "def gis_english_word(word):\n",
    "    dictionary = dict.fromkeys(wn.words(), None)\n",
    "    try:\n",
    "        x = dictionary[word]\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_english_word('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<WordListCorpusReader in 'C:\\\\Users\\\\Shreya Singh\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\words'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to C:\\Users\\Shreya\n",
      "[nltk_data]     Singh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=2\n",
    "for i in tok:\n",
    "    #for j in i:\n",
    "        if is_english_word(i):\n",
    "            \n",
    "            sepword.append(i)\n",
    "        else:\n",
    "            continue     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-2b356c475c9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "tok.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepword = []\n",
    "fdb=[]\n",
    "word=''\n",
    "for i in 'wildcraft':\n",
    "    word=word+i\n",
    "    if len(word)>2:\n",
    "        if is_english_word(word):\n",
    "            sepword.append(word)\n",
    "fdb.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wildcraft'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wildcraft']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wild']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "fdb=[]\n",
    "count=0\n",
    "words=''\n",
    "for i in tok:\n",
    "    #if len(i)<=2:\n",
    "    #    break\n",
    "    #count=count+1\n",
    "    for j in i:\n",
    "        if (len(sepword1)==count):\n",
    "            break\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                sepword1.append(words)\n",
    "                count = count+1\n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'language',\n",
       " 'less',\n",
       " 'abo',\n",
       " 'about',\n",
       " 'word',\n",
       " 'words',\n",
       " 'more',\n",
       " 'abo',\n",
       " 'about',\n",
       " 'mean',\n",
       " 'meaning',\n",
       " 'behind',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'time',\n",
       " 'lea',\n",
       " 'lear',\n",
       " 'learn',\n",
       " 'learning',\n",
       " 'vocabulary',\n",
       " 'gram',\n",
       " 'gramma',\n",
       " 'grammar',\n",
       " 'will',\n",
       " 'neve',\n",
       " 'never',\n",
       " 'able',\n",
       " 'flu',\n",
       " 'flue',\n",
       " 'fluent',\n",
       " 'fluently',\n",
       " 'speak',\n",
       " 'lan',\n",
       " 'language',\n",
       " 'will',\n",
       " 'have',\n",
       " 'lit',\n",
       " 'little',\n",
       " 'talk',\n",
       " 'abo',\n",
       " 'about',\n",
       " 'short',\n",
       " 'give',\n",
       " 'opportunity',\n",
       " 'under',\n",
       " 'understand',\n",
       " 'big',\n",
       " 'idea',\n",
       " 'con',\n",
       " 'context']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepword = []\n",
    "ftdb=[]\n",
    "word=''\n",
    "for i in tok:\n",
    "    for j in i:\n",
    "        if len(stepword)==i:\n",
    "            break\n",
    "        word=word+j\n",
    "        if len(word)>2:\n",
    "            if gis_english_word(word):\n",
    "                stepword.append(word)\n",
    "    word = \"\"\n",
    "stepword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "is\n",
      "less\n",
      "about\n",
      "words\n",
      "and\n",
      "more\n",
      "about\n",
      "the\n",
      "meaning\n",
      "behind\n",
      "them\n",
      "if\n",
      "you\n",
      "spend\n",
      "all\n",
      "your\n",
      "time\n",
      "learning\n",
      "vocabulary\n",
      "and\n",
      "grammar\n",
      "you\n",
      "will\n",
      "never\n",
      "be\n",
      "able\n",
      "to\n",
      "fluently\n",
      "speak\n",
      "a\n",
      "language\n",
      "because\n",
      "you\n",
      "will\n",
      "have\n",
      "little\n",
      "to\n",
      "talk\n",
      "about\n",
      "these\n",
      "short\n",
      "stories\n",
      "give\n",
      "you\n",
      "the\n",
      "opportunity\n",
      "to\n",
      "understand\n",
      "big\n",
      "ideas\n",
      "in\n",
      "context\n"
     ]
    }
   ],
   "source": [
    "for i in tok:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDictionaryNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading PyDictionary-2.0.1-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: click in f:\\ana\\lib\\site-packages (from PyDictionary) (7.1.2)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: requests in f:\\ana\\lib\\site-packages (from PyDictionary) (2.24.0)\n",
      "Collecting goslate\n",
      "  Downloading goslate-1.5.1.tar.gz (17 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in f:\\ana\\lib\\site-packages (from bs4->PyDictionary) (4.9.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\ana\\lib\\site-packages (from requests->PyDictionary) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in f:\\ana\\lib\\site-packages (from requests->PyDictionary) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\ana\\lib\\site-packages (from requests->PyDictionary) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in f:\\ana\\lib\\site-packages (from requests->PyDictionary) (3.0.4)\n",
      "Collecting futures\n",
      "  Downloading futures-3.1.1-py3-none-any.whl (2.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in f:\\ana\\lib\\site-packages (from beautifulsoup4->bs4->PyDictionary) (2.0.1)\n",
      "Building wheels for collected packages: bs4, goslate\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1279 sha256=dec36b9147a8f3ab9900d47a8400a501c6dc59cdcffc78b2e621eaf206a1ba44\n",
      "  Stored in directory: c:\\users\\shreya singh\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "  Building wheel for goslate (setup.py): started\n",
      "  Building wheel for goslate (setup.py): finished with status 'done'\n",
      "  Created wheel for goslate: filename=goslate-1.5.1-py3-none-any.whl size=11554 sha256=f1ae2180d47cfdcb1f39d64c7ee03eb0d0866e48d255aaf85bbdc1663e47ccdb\n",
      "  Stored in directory: c:\\users\\shreya singh\\appdata\\local\\pip\\cache\\wheels\\ce\\7d\\3b\\d13c7465b077ff93da8b99a13a49ffcaada38cf4ce3a6772a8\n",
      "Successfully built bs4 goslate\n",
      "Installing collected packages: bs4, futures, goslate, PyDictionary\n",
      "Successfully installed PyDictionary-2.0.1 bs4-0.0.1 futures-3.1.1 goslate-1.5.1\n"
     ]
    }
   ],
   "source": [
    "pip install PyDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=pd.read_excel('C:\\\\Users\\\\Shreya Singh\\\\Desktop\\\\unigram_freq.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23135851162</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13151942776</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12997637966</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12136980858</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9081174698</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1    2\n",
       "0  23135851162  the\n",
       "1  13151942776   of\n",
       "2  12997637966  and\n",
       "3  12136980858   to\n",
       "4   9081174698    a"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1.drop(column[1],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2], dtype='int64')"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     2\n",
       "0  the\n",
       "2  and\n",
       "3   to\n",
       "4    a\n",
       "5   in"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-222-9179cd738b70>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-222-9179cd738b70>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    temp2=temp1[2,axis=1]\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "temp2=temp1[2,axis=1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23135851162</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13151942776</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12997637966</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12136980858</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9081174698</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count word\n",
       "0  23135851162  the\n",
       "1  13151942776   of\n",
       "2  12997637966  and\n",
       "3  12136980858   to\n",
       "4   9081174698    a"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3=pd.read_excel('C:\\\\Users\\\\Shreya Singh\\\\Desktop\\\\unigram_frequency.xls')\n",
    "temp3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3.drop('count', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word\n",
       "0  the\n",
       "1   of\n",
       "2  and\n",
       "3   to\n",
       "4    a"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaningful_word(word):\n",
    "    try:\n",
    "        for i in temp3[\"word\"].tolist() :\n",
    "            if i == word:\n",
    "                return True\n",
    "        return False\n",
    "    except KeyError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meaningful_word('language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'less',\n",
       " 'about',\n",
       " 'word',\n",
       " 'and',\n",
       " 'mor',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'you',\n",
       " 'time',\n",
       " 'lea',\n",
       " 'vocabular',\n",
       " 'and',\n",
       " 'gra',\n",
       " 'you',\n",
       " 'will',\n",
       " 'neve',\n",
       " 'able',\n",
       " 'flu',\n",
       " 'speak',\n",
       " 'lan',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'lit',\n",
       " 'tal',\n",
       " 'about',\n",
       " 'the',\n",
       " 'sho',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'unde',\n",
       " 'big',\n",
       " 'ide',\n",
       " 'con']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "temp = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                temp.append(words)\n",
    "                sepword1.append(temp[0])\n",
    "                if len(temp)==1:\n",
    "                    break\n",
    "\n",
    "    temp = []            \n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'is',\n",
       " 'les',\n",
       " 'abo',\n",
       " 'wor',\n",
       " 'and',\n",
       " 'mor',\n",
       " 'abo',\n",
       " 'the',\n",
       " 'mea',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'if',\n",
       " 'you',\n",
       " 'spe',\n",
       " 'all',\n",
       " 'you',\n",
       " 'tim',\n",
       " 'lea',\n",
       " 'voc',\n",
       " 'and',\n",
       " 'gra',\n",
       " 'you',\n",
       " 'wil',\n",
       " 'nev',\n",
       " 'be',\n",
       " 'abl',\n",
       " 'to',\n",
       " 'flu',\n",
       " 'spe',\n",
       " 'lan',\n",
       " 'bec',\n",
       " 'you',\n",
       " 'wil',\n",
       " 'hav',\n",
       " 'lit',\n",
       " 'to',\n",
       " 'tal',\n",
       " 'abo',\n",
       " 'the',\n",
       " 'sho',\n",
       " 'sto',\n",
       " 'giv',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opp',\n",
       " 'to',\n",
       " 'und',\n",
       " 'big',\n",
       " 'ide',\n",
       " 'in',\n",
       " 'con']"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "temp = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    if len(i)==2:\n",
    "        if meaningful_word(i):\n",
    "            sepword1.append(i)\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if meaningful_word(words):\n",
    "                temp.append(words)\n",
    "                sepword1.append(temp[0])\n",
    "                if len(temp)==1:\n",
    "                    break\n",
    "\n",
    "    temp = []            \n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'is',\n",
       " 'less',\n",
       " 'about',\n",
       " 'word',\n",
       " 'and',\n",
       " 'mor',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'if',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'you',\n",
       " 'time',\n",
       " 'lea',\n",
       " 'vocabular',\n",
       " 'and',\n",
       " 'gra',\n",
       " 'you',\n",
       " 'will',\n",
       " 'neve',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'flu',\n",
       " 'speak',\n",
       " 'lan',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'lit',\n",
       " 'to',\n",
       " 'tal',\n",
       " 'about',\n",
       " 'the',\n",
       " 'sho',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'unde',\n",
       " 'big',\n",
       " 'ide',\n",
       " 'in',\n",
       " 'con']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "temp = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    if len(i)==2:\n",
    "        if is_english_word(i):\n",
    "            sepword1.append(i)\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                temp.append(words)\n",
    "                sepword1.append(temp[0])\n",
    "                if len(temp)==1:\n",
    "                    break\n",
    "\n",
    "    temp = []            \n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "strf=\" \".join(x for x in sepword1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lan is less about word and mor about the mean behind the if you spend all you time lea vocabular and gra you will neve be able to flu speak lan because you will have lit to tal about the sho give you the opportunity to unde big ide in con'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strf.find('you') #which isn't correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.finditer('you', strf)\n",
    "matches_positions = [match.start() for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 74, 105, 152, 196]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
