{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\ana\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process, fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "def clean_tweet(str1):\n",
    "    word=re.sub(r'^RT[\\s]+','',str1)\n",
    "    word=re.sub(r'\\$\\w*','',word)\n",
    "    word=re.sub(r'https?:\\/\\/.*[\\r\\n]*','',word)\n",
    "    word=re.sub(r'#','',word)\n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens=tokenizer.tokenize(str1)\n",
    "    word_clean=[]\n",
    "    for words in tweet_tokens:\n",
    "        if words not in string.punctuation:\n",
    "            words=words.lower()\n",
    "            word_clean.append(words)\n",
    "    return word_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'about',\n",
       " 'all',\n",
       " 'and',\n",
       " 'anxious',\n",
       " 'anything',\n",
       " 'be',\n",
       " 'but',\n",
       " 'by',\n",
       " 'christ',\n",
       " 'do',\n",
       " 'every',\n",
       " 'god',\n",
       " 'guard',\n",
       " 'hearts',\n",
       " 'in',\n",
       " 'jesus',\n",
       " 'minds',\n",
       " 'not',\n",
       " 'of',\n",
       " 'peace',\n",
       " 'petition',\n",
       " 'prayer',\n",
       " 'present',\n",
       " 'requests',\n",
       " 'situation',\n",
       " 'thanksgiving',\n",
       " 'the',\n",
       " 'to',\n",
       " 'transcends',\n",
       " 'understanding',\n",
       " 'which',\n",
       " 'will',\n",
       " 'with',\n",
       " 'your'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence='Do not be anxious about anything, but in every situation, by prayer and petition, with thanksgiving, present your requests to God. And the peace of God, which transcends all understanding, will guard your hearts and your minds in Christ Jesus.'\n",
    "temp=clean_tweet(sentence)\n",
    "temp=set(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guard', 59), ('your', 38), ('your', 38), ('your', 38), ('about', 35)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract('bottle guard', temp, scorer=fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christ', 67),\n",
       " ('understanding', 48),\n",
       " ('situation', 38),\n",
       " ('prayer', 33),\n",
       " ('thanksgiving', 33)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract('Christianity', temp, scorer=fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anything', 40),\n",
       " ('which', 33),\n",
       " ('guard', 33),\n",
       " ('minds', 33),\n",
       " ('thanksgiving', 32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract('Kashmir', temp, scorer=fuzz.token_sort_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('peace', 77)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract('peaceful', temp, scorer=fuzz.token_sort_ratio,limit=1) #can do this for most resembling word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_word(str1,word):\n",
    "    clean_words=clean_tweet(str1)\n",
    "    clean_words=set(clean_words)\n",
    "    i=process.extract(word, clean_words, scorer=fuzz.token_sort_ratio,limit=5) #can change 'limit' seeing the threshold of i\n",
    "    print(i)\n",
    "    alpha=list(zip(*i))\n",
    "    beta=alpha[0]\n",
    "    #word_to_find = re.findall('\\w+', beta) if the list is alphanumeric\n",
    "    pos=[]\n",
    "    for x in beta:\n",
    "        matches = re.finditer(x, str1)\n",
    "        matches_positions = [match.start() for match in matches]\n",
    "        pos.append(matches_positions)\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('all', 57), ('and', 29), ('will', 25), ('about', 22), ('which', 22)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[170], [68, 131, 181, 212], [189], [18], [153]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_word(sentence.lower(),'calm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hearts', 80), ('requests', 47), ('jesus', 43), ('peace', 43), ('christ', 40)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[205], [114], [237], [139], [230]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_word(sentence.lower(),'heartless')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('christ', 67), ('understanding', 48), ('situation', 38), ('thanksgiving', 33), ('hearts', 33)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[230], [174], [47], [87], [205]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_word(sentence.lower(),'Christianity')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
