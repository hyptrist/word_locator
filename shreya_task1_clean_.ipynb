{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(str1):\n",
    "    '''\n",
    "    If it's a tweet remove this from comment\n",
    "    word=re.sub(r'^RT[\\s]+','',str1) \n",
    "    word=re.sub(r'\\$\\w*','',word)\n",
    "    word=re.sub(r'https?:\\/\\/.*[\\r\\n]*','',word)\n",
    "    '''\n",
    "    word=re.sub(r'#','',str1)\n",
    "    tokenizer=TweetTokenizer(preserve_case=False,strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens=tokenizer.tokenize(word)\n",
    "    word_clean=[]\n",
    "    for words in tweet_tokens:\n",
    "        if words not in string.punctuation:\n",
    "            word_clean.append(words)\n",
    "    return word_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['language',\n",
       " 'is',\n",
       " 'less',\n",
       " 'about',\n",
       " 'words',\n",
       " 'and',\n",
       " 'more',\n",
       " 'about',\n",
       " 'the',\n",
       " 'meaning',\n",
       " 'behind',\n",
       " 'them',\n",
       " 'if',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'your',\n",
       " 'time',\n",
       " 'learning',\n",
       " 'vocabulary',\n",
       " 'and',\n",
       " 'grammar',\n",
       " 'you',\n",
       " 'will',\n",
       " 'never',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'fluently',\n",
       " 'speak',\n",
       " 'a',\n",
       " 'language',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'little',\n",
       " 'to',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'these',\n",
       " 'short',\n",
       " 'stories',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'understand',\n",
       " 'big',\n",
       " 'ideas',\n",
       " 'in',\n",
       " 'context',\n",
       " 'lan']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence='Language is less about words and more about the meaning behind them. If you spend all your time learning vocabulary and grammar, you will never be able to fluently speak a language because you will have little to talk about. These short stories give you the opportunity to understand big ideas in context. #lan'\n",
    "tok=clean_tweet(sentence)\n",
    "tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words as nltk_words\n",
    "def is_english_word(word):\n",
    "    # creation of this dictionary would be done outside of \n",
    "    #     the function because you only need to do it once.\n",
    "    dictionary = dict.fromkeys(nltk_words.words(), None)\n",
    "    try:\n",
    "        x = dictionary[word]\n",
    "        return True\n",
    "    except KeyError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wild']\n",
      "['wildcraft']\n"
     ]
    }
   ],
   "source": [
    "sepword = []\n",
    "fdb=[]\n",
    "word=''\n",
    "for i in 'wildcraft':\n",
    "    word=word+i\n",
    "    if len(word)>2:\n",
    "        if is_english_word(word):\n",
    "            sepword.append(word)\n",
    "fdb.append(word)\n",
    "print(sepword)\n",
    "print(fdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepword1 = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                sepword1.append(words)\n",
    "    words = \"\"\n",
    "#sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppose if a word is grammar, the above code is printing gra, gram and grammar. So the code needs to be further modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'less',\n",
       " 'about',\n",
       " 'word',\n",
       " 'and',\n",
       " 'mor',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'you',\n",
       " 'time',\n",
       " 'lea',\n",
       " 'vocabular',\n",
       " 'and',\n",
       " 'gra',\n",
       " 'you',\n",
       " 'will',\n",
       " 'neve',\n",
       " 'able',\n",
       " 'flu',\n",
       " 'speak',\n",
       " 'lan',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'lit',\n",
       " 'tal',\n",
       " 'about',\n",
       " 'the',\n",
       " 'sho',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'unde',\n",
       " 'big',\n",
       " 'ide',\n",
       " 'con',\n",
       " 'lan']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "temp = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                temp.append(words)\n",
    "                sepword1.append(temp[0])\n",
    "                if len(temp)==1:\n",
    "                    break\n",
    "\n",
    "    temp = []            \n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lan',\n",
       " 'is',\n",
       " 'less',\n",
       " 'about',\n",
       " 'word',\n",
       " 'and',\n",
       " 'mor',\n",
       " 'about',\n",
       " 'the',\n",
       " 'mean',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'if',\n",
       " 'you',\n",
       " 'spend',\n",
       " 'all',\n",
       " 'you',\n",
       " 'time',\n",
       " 'lea',\n",
       " 'vocabular',\n",
       " 'and',\n",
       " 'gra',\n",
       " 'you',\n",
       " 'will',\n",
       " 'neve',\n",
       " 'be',\n",
       " 'able',\n",
       " 'to',\n",
       " 'flu',\n",
       " 'speak',\n",
       " 'lan',\n",
       " 'because',\n",
       " 'you',\n",
       " 'will',\n",
       " 'have',\n",
       " 'lit',\n",
       " 'to',\n",
       " 'tal',\n",
       " 'about',\n",
       " 'the',\n",
       " 'sho',\n",
       " 'give',\n",
       " 'you',\n",
       " 'the',\n",
       " 'opportunity',\n",
       " 'to',\n",
       " 'unde',\n",
       " 'big',\n",
       " 'ide',\n",
       " 'in',\n",
       " 'con',\n",
       " 'lan']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepword1 = []\n",
    "temp = []\n",
    "words=''\n",
    "for i in tok:\n",
    "    if len(i)==2:\n",
    "        if is_english_word(i):\n",
    "            sepword1.append(i)\n",
    "    for j in i:\n",
    "        words=words+j\n",
    "        if (len(words)>2):\n",
    "            if is_english_word(words):\n",
    "                temp.append(words)\n",
    "                sepword1.append(temp[0])\n",
    "                if len(temp)==1:\n",
    "                    break\n",
    "\n",
    "    temp = []            \n",
    "    words = \"\"\n",
    "sepword1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lan is less about word and mor about the mean behind the if you spend all you time lea vocabular and gra you will neve be able to flu speak lan because you will have lit to tal about the sho give you the opportunity to unde big ide in con lan'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strf=\" \".join(x for x in sepword1)\n",
    "strf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 74, 105, 152, 196]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.finditer('you', strf)\n",
    "matches_positions = [match.start() for match in matches]\n",
    "matches_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 140, 239]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.finditer('lan', strf)\n",
    "matches_positions = [match.start() for match in matches]\n",
    "matches_positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
